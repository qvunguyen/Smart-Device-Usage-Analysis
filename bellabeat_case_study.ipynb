{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phase 1: ASK","metadata":{}},{"cell_type":"markdown","source":"The business tasks in this scenario include:\n\n1. Analyzing smart device fitness data: The junior data analyst is tasked with analyzing smart device data related to one of Bellabeat's products to gain insight into how consumers are using their smart devices. The purpose of this analysis is to identify trends and patterns that can inform Bellabeat's marketing strategy.\n\n2. Developing marketing strategy recommendations: Based on the analysis of smart device data, the data analyst is also responsible for providing high-level recommendations for Bellabeat's marketing strategy. The recommendations should be based on insights from the data and should align with Bellabeat's overall mission and business goals.\n\nThe key stakeholders in this scenario include:\n\n1. Urška Sršen: As Bellabeat's cofounder and Chief Creative Officer, Sršen is responsible for driving the company's growth and innovation. She has identified the need to analyze smart device data as a way to unlock new growth opportunities for the company, and has tasked the marketing analytics team with this responsibility.\n\n2. Sando Mur: As a mathematician and Bellabeat's cofounder, Mur is a key member of the executive team. He is likely to be involved in the decision-making process related to the marketing strategy recommendations that come out of the data analysis.\n\n3. Bellabeat marketing analytics team: This team of data analysts is responsible for collecting, analyzing, and reporting data that helps guide Bellabeat's marketing strategy. The junior data analyst who is the main character in this scenario is a member of this team.\n\n4. Bellabeat customers: The insights and recommendations generated from the smart device data analysis and marketing strategy development will ultimately impact Bellabeat's customers. The goal is to use the data to create marketing strategies that better meet their needs and preferences.","metadata":{}},{"cell_type":"markdown","source":"# Phase 2: Prepare","metadata":{}},{"cell_type":"markdown","source":"**Determine the credibility of the data.**\n\nIt is stored in CSV files and organized in long format. It is rated 10/10 for usability on Kaggle, and the original data source can be located and cited using a DOI. The data appears to be comprehensive and updated regularly. However, it is unclear whether there are any issues with bias in the data. Licensing, privacy, security, and accessibility are addressed by examining the original data source. The data's integrity is assumed to be valid as it has a license, acknowledgement for the authors, and the consent from the users","metadata":{}},{"cell_type":"markdown","source":"# Import neccessary library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:29.949940Z","iopub.execute_input":"2023-02-19T04:10:29.951054Z","iopub.status.idle":"2023-02-19T04:10:29.958169Z","shell.execute_reply.started":"2023-02-19T04:10:29.950989Z","shell.execute_reply":"2023-02-19T04:10:29.956922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Set the path to the input folder in Kaggle\npath = \"../input/fitbit/Fitabase Data 4.12.16-5.12.16\"\n\n# Get a list of all files in the input folder\nall_files = os.listdir(path)\n\n# Select only CSV files\ncsv_files = [file for file in all_files if file.endswith(\".csv\")]\n\n# Group the CSV files by their filename\ndaily_files = [file for file in csv_files if \"daily\" in file.lower()]\nhourly_files = [file for file in csv_files if \"hourly\" in file.lower()]\nminute_files = [file for file in csv_files if \"minute\" in file.lower()]\nother_files = [file for file in csv_files if file not in daily_files and file not in hourly_files and file not in minute_files]\n\n# Create empty dictionaries to store the dataframes\ndaily_dfs = {}\nhourly_dfs = {}\nminute_dfs = {}\nother_dfs = {}\n\n# Store the daily files into the \"daily_dfs\" dictionary\nfor file in daily_files:\n    filename, file_extension = os.path.splitext(file)\n    df = pd.read_csv(os.path.join(path, file))\n    daily_dfs[filename] = df\n\n# Store the hourly files into the \"hourly_dfs\" dictionary\nfor file in hourly_files:\n    filename, file_extension = os.path.splitext(file)\n    df = pd.read_csv(os.path.join(path, file))\n    hourly_dfs[filename] = df\n\n# Store the minute files into the \"minute_dfs\" dictionary\nfor file in minute_files:\n    filename, file_extension = os.path.splitext(file)\n    df = pd.read_csv(os.path.join(path, file))\n    minute_dfs[filename] = df\n\n# Store the other files into the \"other_dfs\" dictionary\nfor file in other_files:\n    filename, file_extension = os.path.splitext(file)\n    df = pd.read_csv(os.path.join(path, file))\n    other_dfs[filename] = df\n\n# Group all dataframes into a list\ndata_frames = [daily_dfs, hourly_dfs, minute_dfs, other_dfs]\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T04:10:29.960712Z","iopub.execute_input":"2023-02-19T04:10:29.962105Z","iopub.status.idle":"2023-02-19T04:10:36.026684Z","shell.execute_reply.started":"2023-02-19T04:10:29.962048Z","shell.execute_reply":"2023-02-19T04:10:36.025723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Phase 3: Process","metadata":{}},{"cell_type":"markdown","source":"# Data cleaning","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Handling missing value (remove/fill)","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nfor df_dict in data_frames:\n    for filename, df in df_dict.items():\n        print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n        print(filename)\n        print(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:36.028050Z","iopub.execute_input":"2023-02-19T04:10:36.029026Z","iopub.status.idle":"2023-02-19T04:10:36.472229Z","shell.execute_reply.started":"2023-02-19T04:10:36.028983Z","shell.execute_reply":"2023-02-19T04:10:36.470734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In general, the data is relatively complete. There is not many missing values except for the 'weightLogInfo_merged' data. There are 65 rows with missing value regardless of 'Fat' column. That is almost 100% missing (65/67). Hence there is no point of keeping this collumn so I am going to remove it. Also I will choose to remove missing values in this project instead of filling in missing values because there is not many missing values so when we remove rows with missing values we still have enough data to answer the busines objectives.","metadata":{}},{"cell_type":"code","source":"# Drop the 'Fat' column of the weightLogInfo_merged dataset\n#because there are only two rows contain value in that column\nother_dfs['weightLogInfo_merged'].drop(columns=[\"Fat\"], inplace=True, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:36.473671Z","iopub.execute_input":"2023-02-19T04:10:36.474072Z","iopub.status.idle":"2023-02-19T04:10:36.491185Z","shell.execute_reply.started":"2023-02-19T04:10:36.474039Z","shell.execute_reply":"2023-02-19T04:10:36.489510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove missing values\nfor df_dict in data_frames:\n    for filename, df in df_dict.items():\n        df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:36.494300Z","iopub.execute_input":"2023-02-19T04:10:36.494794Z","iopub.status.idle":"2023-02-19T04:10:37.369049Z","shell.execute_reply.started":"2023-02-19T04:10:36.494725Z","shell.execute_reply":"2023-02-19T04:10:37.367670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Remove any duplicates","metadata":{}},{"cell_type":"code","source":"for df_dict in data_frames:\n    for filename, df in df_dict.items():\n        df.drop_duplicates(inplace=True)\n        \n        #Reset the index\n        df.reset_index(drop=True, inplace=True)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:37.370811Z","iopub.execute_input":"2023-02-19T04:10:37.371728Z","iopub.status.idle":"2023-02-19T04:10:40.479340Z","shell.execute_reply.started":"2023-02-19T04:10:37.371686Z","shell.execute_reply":"2023-02-19T04:10:40.478276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Format string data (if applicable)","metadata":{}},{"cell_type":"markdown","source":"Taking a look at the dataset, there is no columns with string data so this step is not needed. ","metadata":{}},{"cell_type":"markdown","source":"## Step 4: Handling outliers (remove/handle)","metadata":{}},{"cell_type":"code","source":"# determine outlier\nfor df_dict in data_frames:\n    for filename, df in df_dict.items():\n        #Exclude dataset contains \"boolean\" data\n        if filename == \"weightLogInfo_merged\":\n            continue\n        Q1 = df.quantile(0.25)\n        Q3 = df.quantile(0.75)\n        IQR = Q3 - Q1\n        \n        #Remove outliers\n        df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:40.480803Z","iopub.execute_input":"2023-02-19T04:10:40.481800Z","iopub.status.idle":"2023-02-19T04:10:43.472073Z","shell.execute_reply.started":"2023-02-19T04:10:40.481757Z","shell.execute_reply":"2023-02-19T04:10:43.470761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is common for some individuals who are highly active exists in the dataset, so I choose remove them from the dataset to avoid their data to skew the dataset too much. However, it is best practice to investigate each outlier before deciding whether to remove or standardise them because outliers data may contain useful phenomeno.","metadata":{}},{"cell_type":"markdown","source":"## Step 5: Convert data types (if applicable)","metadata":{}},{"cell_type":"markdown","source":"There is no need for this step in this project","metadata":{}},{"cell_type":"markdown","source":"# Data summary and manipulation","metadata":{}},{"cell_type":"markdown","source":"### Summary","metadata":{}},{"cell_type":"markdown","source":"After investigate the data, I recognise the datasets related to physcial activity are broken down into daily, hourly, minute. However, all of them have been merged into 'dailyActivity_merged.csv' file.  I will only use that file to find the insights for physical activities since it is enough to complete the business goals.","metadata":{}},{"cell_type":"code","source":"# Perform data summary for each of the pandas DataFrames\nfor df_dict in data_frames:\n    for filename, df in df_dict.items():\n        if filename in ['dailyActivity_merged', 'sleepDay_merged', 'heartrate_seconds_merged', 'weightLogInfo_merged']:\n            print(\"=================================================================================\")\n            print(f\"Data summary for file {filename}:\")\n            # Count the number of unique values in the \"Id\" column\n            unique_id_count = df[\"Id\"].nunique()\n\n            # Print the result\n            print(f\"The number of unique Id values is: {unique_id_count}\")\n            print(df.info())\n            print(df.describe())\n            print(\"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:31:39.761229Z","iopub.execute_input":"2023-02-19T04:31:39.761703Z","iopub.status.idle":"2023-02-19T04:31:40.055141Z","shell.execute_reply.started":"2023-02-19T04:31:39.761667Z","shell.execute_reply":"2023-02-19T04:31:40.053768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the summary above we can observer the following:\n- 33 people provide data for physical activities\n- 24 people provide data for sleep \n- 14 people provide data for heart rate\n- 8 people provide data for weight","metadata":{}},{"cell_type":"markdown","source":"### Manipulation","metadata":{}},{"cell_type":"markdown","source":"I will add two more extra collumn to the 'daily_activity_merged' dataset called 'weekday', showing what day of the week for the current day, and 'TotalActiveMinutes', which sum up active minutes of the given day.","metadata":{}},{"cell_type":"markdown","source":"### Daily activity","metadata":{}},{"cell_type":"code","source":"daily_activity_df = daily_dfs['dailyActivity_merged']\n# Create a new column with the weekdays\ndaily_activity_df['ActivityDate'] = pd.to_datetime(daily_activity_df[\"ActivityDate\"])\ndaily_activity_df['weekday'] = daily_activity_df['ActivityDate'].dt.day_name()\ndaily_activity_df['TotalActiveMinutes'] = daily_activity_df['FairlyActiveMinutes'] + daily_activity_df['LightlyActiveMinutes'] + daily_activity_df['VeryActiveMinutes']\n\n# Rename the columns\ndaily_activity_df = daily_activity_df.rename(columns={'ActivityDate': 'date'})\n\ndaily_activity_df['date'] = pd.to_datetime(daily_activity_df[\"date\"])\n\n\n\ndaily_activity_df.to_csv('daily_activity_updated.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:45.161435Z","iopub.execute_input":"2023-02-19T04:10:45.161774Z","iopub.status.idle":"2023-02-19T04:10:45.203092Z","shell.execute_reply.started":"2023-02-19T04:10:45.161721Z","shell.execute_reply":"2023-02-19T04:10:45.201830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"daily_activity_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:10:45.204501Z","iopub.execute_input":"2023-02-19T04:10:45.204943Z","iopub.status.idle":"2023-02-19T04:10:45.232096Z","shell.execute_reply.started":"2023-02-19T04:10:45.204903Z","shell.execute_reply":"2023-02-19T04:10:45.230840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Heart Rate","metadata":{}},{"cell_type":"markdown","source":"For the heart rate data, I will separate 'Time' column into 2 different columns named 'date', contains date information, and 'time', contain time information. Also, I create an extra column name 'Time_Category' to classify time of the day into 4 different group: morning (5am to 12pm), afternoon(12pm to 17pm), evening(17pm to 12am), and night (12am to 5am).","metadata":{}},{"cell_type":"code","source":"heart_rate_df = other_dfs[\"heartrate_seconds_merged\"] \nheart_rate_df['Time'] = pd.to_datetime(heart_rate_df[\"Time\"])\n# Create a new column with the weekdays\nheart_rate_df['weekday'] = heart_rate_df['Time'].dt.day_name()\n# Extract the date and time information into separate columns\nheart_rate_df['date'] = heart_rate_df['Time'].dt.date\nheart_rate_df['time'] = heart_rate_df['Time'].dt.time\nheart_rate_df = heart_rate_df.drop('Time', axis=1)\n\n# Define a function to classify time into categories\ndef classify_time(t):\n    hour = t.hour\n    if 5 <= hour < 12:\n        return 'morning'\n    elif 12 <= hour < 17:\n        return 'afternoon'\n    elif 17 <= hour < 21:\n        return 'evening'\n    else:\n        return 'night'\n\n\n# Apply the function to the 'Time' column to create a new column 'Time_Category'\nheart_rate_df['Time_Category'] = heart_rate_df['time'].apply(classify_time)\n\n#Export to new csv file\nheart_rate_df.to_csv('hear_rate_updated.csv', index=False)\n\n# Show the resulting dataframe\nheart_rate_df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-19T04:10:45.233632Z","iopub.execute_input":"2023-02-19T04:10:45.234014Z","iopub.status.idle":"2023-02-19T04:16:01.978121Z","shell.execute_reply.started":"2023-02-19T04:10:45.233979Z","shell.execute_reply":"2023-02-19T04:16:01.976838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After that, I compute the average heart of people and group them by Id and weekday for later analysis","metadata":{}},{"cell_type":"code","source":"# group the dataframe by 'Id' and 'weekday' and compute the mean of 'Value'\nheart_rate_mean = heart_rate_df.groupby(['Id', 'weekday','date'])['Value'].mean()\n\n# reset the index of the resulting dataframe to make 'Id' and 'weekday' columns again\nheart_rate_mean = heart_rate_mean.reset_index()\n\n# Rename the columns\nheart_rate_mean = heart_rate_mean.rename(columns={'Value': 'AvgHeartRate'})\n\n# print the resulting dataframe\nheart_rate_mean.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:16:01.979998Z","iopub.execute_input":"2023-02-19T04:16:01.980714Z","iopub.status.idle":"2023-02-19T04:16:02.579965Z","shell.execute_reply.started":"2023-02-19T04:16:01.980666Z","shell.execute_reply":"2023-02-19T04:16:02.578757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sleep","metadata":{}},{"cell_type":"markdown","source":"Similarly, for sleep datset, I breakdown the 'SleepDay' column in to 'date' and 'time'. Then I added an additional column called 'weekday' to classify what day of week is that for the date.","metadata":{}},{"cell_type":"code","source":"sleep_df = other_dfs['sleepDay_merged']\nsleep_df['SleepDay'] = pd.to_datetime(sleep_df[\"SleepDay\"])\n# Extract the date and time information into separate columns\nsleep_df['date'] = sleep_df['SleepDay'].dt.date\nsleep_df['time'] = sleep_df['SleepDay'].dt.time\n\n# Create a new column with the weekdays\nsleep_df['weekday'] = sleep_df['SleepDay'].dt.day_name()\n\n#Drop the SleepDay column\nsleep_df = sleep_df.drop('SleepDay', axis=1)\n\n#Export to new csv file\nsleep_df.to_csv('sleep_updated.csv', index=False)\n\n# sleep_df = sleep_df.drop('Time', axis=1)\nsleep_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:16:02.600876Z","iopub.execute_input":"2023-02-19T04:16:02.601232Z","iopub.status.idle":"2023-02-19T04:16:02.632833Z","shell.execute_reply.started":"2023-02-19T04:16:02.601201Z","shell.execute_reply":"2023-02-19T04:16:02.631503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I compute the total minutes a sleep and group the by Id and weekday for later analysis","metadata":{}},{"cell_type":"code","source":"# group the dataframe by 'Id', 'weekday', and 'date', and compute the mean of 'TotalMinutesSleep' and 'TotalTimeInBed'\nsleep_mean = sleep_df.groupby(['Id', 'weekday', 'date'])[['TotalMinutesAsleep', 'TotalTimeInBed']].mean()\n\n# reset the index of the resulting dataframe to make 'Id', 'weekday', and 'date' columns again\nsleep_mean = sleep_mean.reset_index()\n\n# print the resulting dataframe\nsleep_mean.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:16:02.634591Z","iopub.execute_input":"2023-02-19T04:16:02.636029Z","iopub.status.idle":"2023-02-19T04:16:02.656716Z","shell.execute_reply.started":"2023-02-19T04:16:02.635971Z","shell.execute_reply":"2023-02-19T04:16:02.655808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge activity, heart rate, sleep","metadata":{}},{"cell_type":"raw","source":"For any of the Id contained in all physical data, sleep, and hear raet, I merge them into a single 'csv' file to study the correlation between physical activities, heart rate, and sleep.","metadata":{}},{"cell_type":"code","source":"# Convert the 'date' column to datetime data type\ndaily_activity_df['date'] = pd.to_datetime(daily_activity_df['date'])\nheart_rate_mean['date'] = pd.to_datetime(heart_rate_mean['date'])\nsleep_mean['date'] = pd.to_datetime(sleep_mean['date'])\n\n# Merge dataframes on 'Id' and 'date' columns\ndf_merged = pd.merge(daily_activity_df, heart_rate_mean, on=['Id', 'date'])\ndf_merged = pd.merge(df_merged, sleep_mean, on=['Id', 'date'])\ndf_merged = df_merged.drop('weekday_x', axis=1)\ndf_merged = df_merged.drop('weekday_y', axis=1)\n\n#Export to new csv file\ndf_merged.to_csv('master_merge.csv', index=False)\n\n# Print the merged dataframe\ndf_merged.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:16:02.657888Z","iopub.execute_input":"2023-02-19T04:16:02.658867Z","iopub.status.idle":"2023-02-19T04:16:02.716521Z","shell.execute_reply.started":"2023-02-19T04:16:02.658826Z","shell.execute_reply":"2023-02-19T04:16:02.715082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data visualisation & Analysis","metadata":{}},{"cell_type":"markdown","source":"### Physical activity","metadata":{}},{"cell_type":"code","source":"# Group the data by weekday and calculate the mean calories burned for each weekday\navg_calories = daily_activity_df.groupby('weekday')['Calories'].mean()\n\n# Sort the value by descending order\navg_calories = avg_calories.sort_values()\n\n# Create a bar graph using Pandas plot function\nax = avg_calories.plot(kind='barh',  figsize = (10,6), color='lightblue', alpha=0.7)\n\n# Set the title and axis labels\nax.set_title('Average Calories Burned by Day of Week', fontsize=14, fontweight='bold')\nax.set_xlabel('Average Calories Burned', fontsize=12)\nax.set_ylabel('Weekday', fontsize=12)\n\n# Add grid lines and remove spines\nax.grid(axis='x', linestyle='--', alpha=0.9)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.yaxis.grid(False)\n\n# Add labels to the bars\nfor i, v in enumerate(avg_calories):\n    ax.text(v + 10, i - 0.1, str(int(v)), color='black', fontsize=10)\n    \n# save the plot to a file\nplt.savefig('avg_cal_burned_by_day.png')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:55.257977Z","iopub.execute_input":"2023-02-19T04:21:55.258721Z","iopub.status.idle":"2023-02-19T04:21:55.588405Z","shell.execute_reply.started":"2023-02-19T04:21:55.258678Z","shell.execute_reply":"2023-02-19T04:21:55.587054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the weekday column as a categorical data type with the desired order\nweekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndaily_activity_df['weekday'] = pd.Categorical(daily_activity_df['weekday'], categories=weekday_order, ordered=True)\n\n# Group the data by weekday and calculate the mean total steps for each weekday\navg_step_by_day = daily_activity_df.groupby('weekday')['TotalSteps'].mean()\n\n# Sort the value by descending order\navg_step_by_day = avg_step_by_day.sort_values()\n\n# Create a bar graph using Pandas plot function\nax = avg_step_by_day.plot(kind='barh',  figsize = (10,6), color='lightblue', alpha=0.7)\n\n# Set the title and axis labels\nax.set_title('Average Total Steps by Day of Week', fontsize=14, fontweight='bold')\nax.set_xlabel('Average Total Steps', fontsize=12)\nax.set_ylabel('Weekday', fontsize=12)\n\n# Add grid lines and remove spines\nax.grid(axis='x', linestyle='--', alpha=0.9)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.yaxis.grid(False)\n\n# Add labels to the bars\nfor i, v in enumerate(avg_step_by_day):\n    ax.text(v + 100, i - 0.1, str(int(v)), color='black', fontsize=10)\n\n# save the plot to a file\nplt.savefig('avg_step_by_day.png')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:55.590905Z","iopub.execute_input":"2023-02-19T04:21:55.591287Z","iopub.status.idle":"2023-02-19T04:21:55.947112Z","shell.execute_reply.started":"2023-02-19T04:21:55.591254Z","shell.execute_reply":"2023-02-19T04:21:55.945957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group the data by weekday and calculate the mean total distance for each weekday\navg_total_dist_by_day = daily_activity_df.groupby('weekday')['TotalDistance'].mean()\n\n# Sort the value by descending order\navg_total_dist_by_day = avg_total_dist_by_day.sort_values()\n\n# Create a bar graph using Pandas plot function\nax = avg_total_dist_by_day.plot(kind='barh',  figsize = (10,6), color='lightblue', alpha=0.7)\n\n# Set the title and axis labels\nax.set_title('Average Total Distance Traveled by Day of Week', fontsize=14, fontweight='bold')\nax.set_xlabel('Average Total Distance (km)', fontsize=12)\nax.set_ylabel('Weekday', fontsize=12)\n\n# Add grid lines and remove spines\nax.grid(axis='x', linestyle='--', alpha=0.9)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.yaxis.grid(False)\n\n# Add labels to the bars\nfor i, v in enumerate(avg_total_dist_by_day):\n    ax.text(v + 0.3, i - 0.1, '{:.1f}'.format(v), color='black', fontsize=10)\n\n# save the plot to a file    \nplt.savefig('avg_dist_by_day.png')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:55.949257Z","iopub.execute_input":"2023-02-19T04:21:55.950063Z","iopub.status.idle":"2023-02-19T04:21:56.283055Z","shell.execute_reply.started":"2023-02-19T04:21:55.950011Z","shell.execute_reply":"2023-02-19T04:21:56.281974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the weekday column as a categorical data type with the desired order\nweekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndaily_activity_df['weekday'] = pd.Categorical(daily_activity_df['weekday'], categories=weekday_order, ordered=True)\n\n# Group the data by weekday and calculate the sum values for each column\navg_activity_by_day = daily_activity_df.groupby('weekday').mean()\n\n# Sort the value by total active minutes in descending order descending order\navg_activity_by_day = avg_activity_by_day.sort_values(by='TotalActiveMinutes')\n\n# Set the colors for the bars\ncolors = ['#4b7bec', '#a55eea', '#f53b57', '#ced6e0', '#ff6b81', '#576574']\n\n# Create a bar graph using Pandas plot function\nax = avg_activity_by_day.plot(kind='barh', y=['TotalActiveMinutes', 'SedentaryMinutes'], figsize = (12,6), color=colors,alpha=0.7)\n\n# Set the title and axis labels\nax.set_title('Average Active Minutes vs Sedentary Minutes by Day of Week', fontsize=14, fontweight='bold')\nax.set_xlabel('Minutes', fontsize=12)\nax.set_ylabel('Weekday', fontsize=12)\n\n# Set the legend\nax.legend(['Active', 'Sedentary'], bbox_to_anchor=(1, 1))\n\n\n\n# Add grid lines and remove spines\nax.grid(axis='y', linestyle='--', alpha=0.9)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# save the plot to a file\nplt.savefig('avg_active_minutes_vs_sedentary_by_day.png')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:56.284824Z","iopub.execute_input":"2023-02-19T04:21:56.285528Z","iopub.status.idle":"2023-02-19T04:21:56.660516Z","shell.execute_reply.started":"2023-02-19T04:21:56.285479Z","shell.execute_reply":"2023-02-19T04:21:56.659642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the weekday column as a categorical data type with the desired order\nweekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndaily_activity_df['weekday'] = pd.Categorical(daily_activity_df['weekday'], categories=weekday_order, ordered=True)\n\n# Set the colors for the bars\ncolors = ['#6ab04c', '#2c3e50', '#3498db']\n\n# Group the data by weekday and calculate the sum values for each column\navg_distance_by_day = daily_activity_df.groupby('weekday').mean()\n\n# Sort the value by total light active in descending order descending order\navg_distance_by_day = avg_distance_by_day.sort_values(by='LightActiveDistance')\n\n# Create a bar graph using Pandas plot function\nax = avg_distance_by_day.plot(kind='barh', y=[\"VeryActiveDistance\",\"ModeratelyActiveDistance\",\"LightActiveDistance\"], figsize=(12, 6), width=0.8, color=colors, alpha=0.8)\n\n# Set the title and axis labels\nax.set_title('Avereage Active Distance by Day of Week', fontsize=14, fontweight='bold')\nax.set_xlabel('Miles', fontsize=12)\nax.set_ylabel('Weekday', fontsize=12)\n\n\n# Add horizontal grid lines\nax.grid(axis='x', linestyle='--', linewidth=0.5, alpha=0.5)\n\n\n# Set the legend\nax.legend(['Very Active', 'Moderate Active', 'Light Active'],\n          bbox_to_anchor=(1, 1))\n\n# save the plot to a file\nplt.savefig('avg_active_distance_by_day.png')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:56.663018Z","iopub.execute_input":"2023-02-19T04:21:56.663952Z","iopub.status.idle":"2023-02-19T04:21:57.103439Z","shell.execute_reply.started":"2023-02-19T04:21:56.663915Z","shell.execute_reply":"2023-02-19T04:21:57.102301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the weekday column as a categorical data type with the desired order\nweekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndaily_activity_df['weekday'] = pd.Categorical(daily_activity_df['weekday'], categories=weekday_order, ordered=True)\n\n# Set the colors for the bars\ncolors = ['#6ab04c', '#2c3e50', '#3498db']\n\n# Group the data by weekday and calculate the sum values for each column\navg_active_minutes_by_day = daily_activity_df.groupby('weekday').mean()\n\n# Sort the value by total light active minutes in descending order descending order\navg_active_minutes_by_day = avg_active_minutes_by_day.sort_values(by='LightlyActiveMinutes')\n\n# Create a bar graph using Pandas plot function\nax = avg_active_minutes_by_day.plot(kind='barh', y=['VeryActiveMinutes', 'FairlyActiveMinutes', 'LightlyActiveMinutes' ], figsize=(12, 6), width=0.8, color=colors, alpha=0.8)\n\n# Set the title and axis labels\nax.set_title('Avereage Active Minutes by Level', fontsize=14, fontweight='bold')\nax.set_xlabel('Minutes', fontsize=12)\nax.set_ylabel('Weekday', fontsize=12)\n\n\n# Add horizontal grid lines\nax.grid(axis='x', linestyle='--', linewidth=0.5, alpha=0.5)\n\n\n# Set the legend\nax.legend(['Very Active', 'Fairly Active', 'Lightly Active'], bbox_to_anchor=(1, 1))\n\n\n# save the plot to a file\nplt.savefig('avg_active_minutes_by_level.png')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:57.105042Z","iopub.execute_input":"2023-02-19T04:21:57.105408Z","iopub.status.idle":"2023-02-19T04:21:57.548054Z","shell.execute_reply.started":"2023-02-19T04:21:57.105375Z","shell.execute_reply":"2023-02-19T04:21:57.546803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Heart Rate","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Compute the average heart rate value using \"Value\" column\nhr_avg = heart_rate_df.groupby([\"weekday\", \"Time_Category\"])[\"Value\"].mean().reset_index()\n\n# Sort the data by the average value of heart rate for \"Time_category\" and then by \"weekday\"\nhr_avg = hr_avg.sort_values([\"Time_Category\", \"Value\"], ascending=[True, False])\n\n# Create a horizontal bar chart\nfig, ax = plt.subplots(figsize=(10, 8))\nsns.barplot(x=\"Value\", y=\"weekday\", hue=\"Time_Category\", data=hr_avg, ax=ax, orient=\"h\", palette='husl')\n\n# Set the title and axes labels\nax.set_title(\"Average Heart Rate by Day of Week and Time of Day\")\nax.set_xlabel(\"Average Heart Rate\")\nax.set_ylabel(\"Weekday\")\n\n# Move the legend to the top right corner\nax.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 1))\n\n# save the plot to a file\nplt.savefig('avg_heart_rate_by_day_and_daytime.png')\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:28:52.399295Z","iopub.execute_input":"2023-02-19T04:28:52.400241Z","iopub.status.idle":"2023-02-19T04:28:53.456571Z","shell.execute_reply.started":"2023-02-19T04:28:52.400191Z","shell.execute_reply":"2023-02-19T04:28:53.455345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sleep","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Compute the average of \"TotalMinutesAsleep\", group it by 'weekday', and sort it in descending order\nsleep_grouped = sleep_df.groupby('weekday')['TotalMinutesAsleep'].mean().sort_values(ascending=False)\n\n# Create a box plot\nfig, ax = plt.subplots(figsize=(10, 6))\nsns.boxplot(x='weekday', y='TotalMinutesAsleep', data=sleep_df, order=sleep_grouped.index, showfliers=False, ax=ax)\n\nplt.title('Average TotalMinutesAsleep by Day of Week')\nplt.xlabel('Weekday')\nplt.ylabel('TotalMinutesAsleep')\n\n# save the plot to a file\nplt.savefig('avg_sleep_by_day.png')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:58.567044Z","iopub.execute_input":"2023-02-19T04:21:58.567930Z","iopub.status.idle":"2023-02-19T04:21:58.910516Z","shell.execute_reply.started":"2023-02-19T04:21:58.567893Z","shell.execute_reply":"2023-02-19T04:21:58.909303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Examine the correlation between variables","metadata":{}},{"cell_type":"code","source":"# Correlation between physcial activities variables\n# Correlation matrix\ncorr = daily_activity_df.corr()\n\n# Plot correlation matrix\nplt.figure(figsize=(12,10))\nplt.title(\"Daily Activity\")\nmask = np.triu(np.ones_like(daily_activity_df.corr(), dtype=bool))\nsns.heatmap(daily_activity_df.corr(), mask=mask, cmap='coolwarm', annot=True)\n\n# save the plot to a file\nplt.savefig('activity_corr_heat_map.png')\n\n#display the heatmap\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:21:58.912168Z","iopub.execute_input":"2023-02-19T04:21:58.912653Z","iopub.status.idle":"2023-02-19T04:22:00.307439Z","shell.execute_reply.started":"2023-02-19T04:21:58.912608Z","shell.execute_reply":"2023-02-19T04:22:00.306225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation between physcial, heart rate, and sleep variable\n# Correlation matrix\ncorr = df_merged.corr()\n\n# Plot correlation matrix\nplt.figure(figsize=(12,10))\nplt.title(\"Daily Activity\")\nmask = np.triu(np.ones_like(df_merged.corr(), dtype=bool))\nsns.heatmap(df_merged.corr(), mask=mask, cmap='coolwarm', annot=True)\n\n# save the plot to a file\nplt.savefig('activity_heartrate_sleep_heatmap.png')\n\n#Display the heat map\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T04:22:14.786598Z","iopub.execute_input":"2023-02-19T04:22:14.787055Z","iopub.status.idle":"2023-02-19T04:22:16.559994Z","shell.execute_reply.started":"2023-02-19T04:22:14.787018Z","shell.execute_reply":"2023-02-19T04:22:16.558751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Phase 4: Anayse","metadata":{}},{"cell_type":"markdown","source":"### Physical activity","metadata":{}},{"cell_type":"markdown","source":"Fitbit trackers measure physical activity in terms of \"active minutes,\" which are the minutes during which you engage in moderate to intense physical activity.\n\nFitbit defines three levels of physical activity:\n\n1. Lightly Active Minutes: These are minutes when you are active, but not necessarily exercising. This might include activities like walking around the house, doing light chores, or standing up from your desk periodically.\n\n2. Fairly Active Minutes: These are minutes when you are engaging in moderate-intensity exercise or activity. This might include activities like brisk walking, cycling, or doing household chores that require a bit more effort.\n\n3. Very Active Minutes: These are minutes when you are engaging in high-intensity exercise or activity. This might include activities like running, hiking, or playing a sport at a competitive level.\n\nFitbit uses its sensors to track your movements and heart rate to determine the level of activity you are engaged in, and then assigns active minutes accordingly. The more active you are, the more active minutes you will accumulate.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"display:flex\">\n    <div style=\"flex:1;padding-right:5px;\">\n        <img src=\"avg_active_minutes_vs_sedentary_by_day.png\">\n    </div>\n    <div style=\"flex:1;padding-left:5px;\">\n        <img src=\"avg_active_minutes_by_level.png\">\n    </div>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"On average, Saturday, Tuesday, and Friday are the top three most active days of the week, with Monday, Wednesday, Thursday, and Sunday following suit. People typically accumulate around 20 minutes of very active minutes and 15 minutes of fairly active minutes per day. However, the level of lightly active minutes varies across the days, with Saturday, Friday, and Tuesday being the top three, followed by Monday, Wednesday, Thursday, and Sunday.\n\nIt is noteworthy that the level of lightly active minutes is a significant factor that distinguishes the most active day from the least active day of the week. These findings suggest that people who engage in more light activities throughout the day tend to be more active overall.","metadata":{}},{"cell_type":"markdown","source":"![avg_cal_burned_by_day](avg_cal_burned_by_day.png)","metadata":{}},{"cell_type":"markdown","source":"In terms of calorie expenditure, it appears that Tuesday, Saturday, and Friday are the top three days where people tend to burn the most calories, followed by Monday, Wednesday, Sunday, and Thursday. This pattern is similar to the distribution of active minutes throughout the week, indicating that there may be a relationship between physical activity and calorie burn. These insights could be valuable in developing strategies to encourage individuals to be more physically active and burn more calories, potentially leading to improved health outcomes.","metadata":{}},{"cell_type":"markdown","source":"![avg_dist_by_day](avg_dist_by_day.png)","metadata":{}},{"cell_type":"markdown","source":"![avg_step_by_day](avg_step_by_day.png)","metadata":{}},{"cell_type":"markdown","source":"Upon analyzing the total distance traveled and total steps taken by day of the week, it becomes evident that Saturday, Tuesday, and Friday are the top three most active days. Interestingly, outdoor activities seem to be more common on Saturday and Tuesday, while indoor activities are more prevalent on Friday. This is reflected in the average total distance traveled and average total steps taken, with Saturday and Tuesday consistently ranking within the top three, while Friday falls to the bottom three in these categories.\n\nGiven that the majority of active minutes are accounted for by light activities, it is reasonable to infer that people engage in outdoor light exercises such as jogging on Saturday and Tuesday, whereas on Friday, indoor activities are more prevalent. These insights can be useful in developing targeted interventions and promoting physical activity by emphasizing outdoor activities as a means of staying active and healthy","metadata":{}},{"cell_type":"markdown","source":"### Heart rate","metadata":{}},{"cell_type":"markdown","source":"![avg_heart_rate_by_day_and_daytime](avg_heart_rate_by_day_and_daytime.png)","metadata":{}},{"cell_type":"markdown","source":"Through an analysis of the average heart rate by day of the week and time of day, we can gain insights into when people tend to engage in high-intensity exercise. Among the top three most active days, we observe that people tend to perform high-intensity exercises in the afternoon on Saturday, and in the evening or afternoon on Tuesday. On Friday, high-intensity exercise is more commonly performed in the evening.\n\nThese findings provide valuable information for fitness product manufacturers and wellness professionals to create personalized recommendations that align with users' schedules and natural tendencies. For instance, they can suggest that people engage in high-intensity exercise during specific times of the day to maximize the benefits of their workout, based on the patterns observed in the data. Furthermore, these insights can inform the design and marketing of fitness products to better meet the needs of consumers, ultimately leading to improved health and wellness outcomes.","metadata":{}},{"cell_type":"markdown","source":"### Sleep","metadata":{}},{"cell_type":"markdown","source":"![average_sleep](avg_sleep_by_day.png)","metadata":{}},{"cell_type":"markdown","source":"The box plot analysis indicates that people tend to have less total sleep time on their most active days, with Saturday, Friday, and Tuesday ranking among the bottom four. Conversely, on the least active days such as Sunday, Wednesday, and Monday, people tend to have more total minutes of sleep on average.\n\nThese insights can be used to develop personalized recommendations for improving sleep habits and overall wellness. For example, on more active days, people may benefit from incorporating activities that promote relaxation and stress reduction to help them wind down before bed. Similarly, on less active days, people may want to consider more physically demanding activities that promote better sleep quality. Additionally, fitness product manufacturers and wellness professionals can use this information to design products that integrate sleep tracking and provide personalized recommendations to users to optimize their sleep and overall health.","metadata":{}},{"cell_type":"markdown","source":"## Summary:","metadata":{}},{"cell_type":"markdown","source":"* Saturday, Tuesday, and Friday are the top three most active days, while Sunday, Wednesday, and Monday are the least active.\n\n* People accumulate around 20 minutes of very active minutes and 15 minutes of fairly active minutes per day.\n \n* Lightly active minutes vary across the days and are a significant factor in distinguishing the most active day from the least active day.\n\n* Tuesday, Saturday, and Friday are the top three days where people tend to burn the most calories, followed by Monday, Wednesday, Sunday, and Thursday.\n\n* Saturday, Tuesday, and Friday are the top three most active days in terms of total distance traveled and total steps taken.\n\n* Outdoor activities seem to be more common on Saturday and Tuesday, while indoor activities are more prevalent on Friday.\n\n* People tend to perform high-intensity exercises in the afternoon on Saturday and in the evening or afternoon on Tuesday, with high-intensity exercise more commonly performed in the evening on Friday.\n\n* People tend to have less total sleep time on their most active days, with Saturday, Friday, and Tuesday ranking among the bottom four.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Phase 5: Share","metadata":{}},{"cell_type":"markdown","source":"## Recommendation for Bellabeat","metadata":{}},{"cell_type":"markdown","source":"Based on the insights provided, Bellabeat can develop a marketing strategy for one of their products as follows:\n\nProduct: Bellabeat fitness tracker\n\nTarget audience: People who are interested in improving their physical activity levels and overall wellness\n\nMarketing Strategy:\n\n1. Promote outdoor activities: Given that outdoor activities are more prevalent on Saturday and Tuesday, Bellabeat can emphasize the benefits of outdoor exercise in its marketing campaigns. For instance, Bellabeat can create social media campaigns featuring pictures of people engaging in outdoor activities, and highlight the health benefits of jogging, hiking, and other outdoor activities.\n\n2. Emphasize the importance of light activities: Bellabeat can use the insight that light activities contribute significantly to overall physical activity levels in its marketing campaigns. The campaigns can focus on how incorporating light activities throughout the day can lead to improved health outcomes.\n\n3. Personalized workout recommendations: Bellabeat can create personalized workout recommendations based on when users tend to engage in high-intensity exercises. For example, if a user tends to engage in high-intensity exercise in the afternoon on Saturdays, Bellabeat can recommend specific high-intensity exercises for that time of day.\n\n4. Improve sleep habits: Bellabeat can use the insight that people tend to have less sleep time on their most active days to develop personalized recommendations for improving sleep habits. Bellabeat can suggest activities that promote relaxation and stress reduction to help users wind down before bed on more active days.\n\n5. Highlight the relationship between physical activity and calorie burn: Bellabeat can emphasize the relationship between physical activity and calorie burn in its marketing campaigns. The campaigns can highlight how being physically active on specific days of the week can lead to increased calorie burn, and ultimately, improved health outcomes.\n\n6. Use social media influencers: Bellabeat can collaborate with social media influencers who are interested in health and wellness to promote its fitness tracker. The influencers can create posts featuring the product and highlight its features and benefits.\n\nOverall, Bellabeat can use the insights provided to develop targeted marketing campaigns that resonate with its target audience and ultimately lead to improved health and wellness outcomes.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}